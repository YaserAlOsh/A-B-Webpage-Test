{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze A/B Test Results\n",
    "\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "- [Introduction](#intro)\n",
    "- [Importing](#importing)\n",
    "- [Part I - Probability](#probability)\n",
    "- [Part II - A/B Test](#ab_test)\n",
    "- [Part III - Regression](#regression)\n",
    "\n",
    "\n",
    "<a id='intro'></a>\n",
    "### Introduction\n",
    "\n",
    "[A/B tests are very commonly performed by data analysts and data scientists.  It is important that you get some practice working with the difficulties of these.]\n",
    "\n",
    "In this project, I will be analyzing the results of an A/B test run by an e-commerce website, with the goal of deciding if the company should implement the new page design, keep the old page, or perhaps run the experiment longer to make their decision.\n",
    "\n",
    "First, to get a sense of the data at hand, we should check for cleanliness and tidiness.\n",
    "\n",
    "<a id='importing'></a>\n",
    "#### Importing\n",
    "\n",
    "\n",
    "\n",
    "To get started, let's import our libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a quick look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0\n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0\n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0\n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0\n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ab_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(294478, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 294478 entries, 0 to 294477\n",
      "Data columns (total 5 columns):\n",
      "user_id         294478 non-null int64\n",
      "timestamp       294478 non-null object\n",
      "group           294478 non-null object\n",
      "landing_page    294478 non-null object\n",
      "converted       294478 non-null int64\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 11.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No missing values, great."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Looking at group and landing_page, it looks like we don't really need them both.  \n",
    "Let's check them first, did they ever not match?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1965"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query('group == \"treatment\" and landing_page == \"old_page\"').shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1928"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query('group == \"control\" and landing_page == \"new_page\"').shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those rows must have been incorrectly given, so I will remove every occurance where control and landing_page columns don't match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(290585, 5)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To drop them, first we get a query of the items that don't match, then we give its index to the drop function.\n",
    "df.drop(df.query('group == \"treatment\" and landing_page != \"new_page\"').index,inplace=True)\n",
    "df.drop(df.query('group == \"control\" and landing_page != \"old_page\"').index,inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double Check all of the incorrect rows were removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this should be 0\n",
    "df[((df['group'] == 'treatment') == (df['landing_page'] == 'new_page')) == False].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this should be 0\n",
    "df[((df['group'] == 'control') == (df['landing_page'] == 'old_page')) == False].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A great deal of rows were dropped.  \n",
    "Now let's check for duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.user_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that we have one duplicate row, let's examine it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-09 05:37:58.781806</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-14 02:55:59.590927</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   timestamp      group landing_page  converted\n",
       "1899   773192  2017-01-09 05:37:58.781806  treatment     new_page          0\n",
       "2893   773192  2017-01-14 02:55:59.590927  treatment     new_page          0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dup = df[df.duplicated(subset=['user_id'],keep=False)]\n",
    "dup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove one of the rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(dup.index[0],inplace=True,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will remove one of the columns, group or landing_page.  \n",
    "It's a matter of preference which one I choose, so I will go for group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['group'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp landing_page  converted\n",
       "0   851104  2017-01-21 22:11:48.556739     old_page          0\n",
       "1   804228  2017-01-12 08:01:45.159739     old_page          0\n",
       "2   661590  2017-01-11 16:55:06.154213     new_page          0\n",
       "3   853541  2017-01-08 18:28:03.143765     new_page          0\n",
       "4   864975  2017-01-21 01:52:26.210827     old_page          1"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='probability'></a>\n",
    "#### Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, now that we have our data clean and tidy, let's do some probabilities to know what to expect.\n",
    "\n",
    "Probability of an individual converting regardless of the page they receive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_convert = df.converted.mean()\n",
    "prop_convert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see if it differs for each page, I will check the old_page users conversion rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1203863045004612"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_mean = df.query('landing_page == \"old_page\"').converted.mean()\n",
    "old_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for the new page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11880806551510564"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_mean = df.query('landing_page == \"new_page\"').converted.mean()\n",
    "new_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many users are on the new page?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000619442226688"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.query('landing_page == \"new_page\"')) / df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From that one could say that there isn't much of a difference between the old page and the new page conversion rate.  \n",
    "Also, since there are almost as many users on new page as on the old page, the ratios computed show that we shouldn't expect the new page to be really better.  \n",
    "But more testing is required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ab_test'></a>\n",
    "### Part II - A/B Test\n",
    "\n",
    "Notice that because of the time stamp associated with each event, you could technically run a hypothesis test continuously as each observation was observed.  \n",
    "\n",
    "However, then the hard question is do you stop as soon as one page is considered significantly better than another or does it need to happen consistently for a certain amount of time?  How long do you run to render a decision that neither page is better than another?  \n",
    "\n",
    "These questions are the difficult parts associated with A/B tests in general.  \n",
    "\n",
    "\n",
    "`1.` For now, consider you need to make the decision just based on all the data provided.  If you want to assume that the old page is better unless the new page proves to be definitely better at a Type I error rate of 5%, what should your null and alternative hypotheses be?  You can state your hypothesis in terms of words or in terms of **$p_{old}$** and **$p_{new}$**, which are the converted rates for the old and new pages.\n",
    "\n",
    "We found out before that it's reasonable to not expect much a difference between the pages performance.  \n",
    "So going from that, we can assume that the new page has the same performance, or worse performance, than the old page _unless it proves otherwise_.  \n",
    "Then, the **null** and **alternative** hypothesis would be as follows:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H0 : Pnew <= Pold$  \n",
    "$H1 : Pnew > Pold$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$p_{old}$** and **$p_{new}$**, are the converted rates for the old and new pages.\n",
    "\n",
    "\n",
    "To start, I will assume that under the null hypothesis $p_{new}$ and $p_{old}$ both have \"true\" success rates equal to the **converted** success rate regardless of page - that is $p_{new}$ and $p_{old}$ are equal. Furthermore, assume they are equal to the **converted** rate in **ab_data.csv** regardless of the page.\n",
    "\n",
    "Then to do the **A/B** Test, I will create a sampling distribution for the difference in **converted rate** between the two pages over 10,000 iterations of calculating an estimate from the null."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the default convert rate $p_{new}$ and $p_{old}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.11959708724499628, 0.11959708724499628)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_new = p_old = prop_convert\n",
    "p_new , p_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the number of users on the new page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145310"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_new = df.query('landing_page == \"new_page\"').user_id.nunique()\n",
    "n_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the number of users on the old page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145274"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_old = df.query('landing_page == \"old_page\"').user_id.nunique()\n",
    "n_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will run some samples as required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulating $n_{new}$ transactions with a conversion rate of $p_{new}$ under the null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_page_converted = np.random.choice([0,1],size=n_new,p=[1-p_new,p_new])\n",
    "new_page_converted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulating $n_{old}$ transactions with a conversion rate of $p_{old}$ under the null. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_page_converted = np.random.choice([0,1],size=n_old,p=[1-p_old,p_old])\n",
    "old_page_converted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing $p_{new}$ - $p_{old}$ for the simulated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0013536767501305946"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_page_converted.mean() - old_page_converted.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From that it seems that the new page in fact performed slightly worse than the old page, but this isn't enough as an evidence, we need to sample a distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will create 10,000 $p_{new}$ - $p_{old}$ values using the same simulation process above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be done in two ways:\n",
    "1. For loop 10000 times, while making a sample and calculating a random.choice for each sample.\n",
    "2. Using the numpy random binomial function.\n",
    "\n",
    "Both of them work but the second is much faster, at least 20x (for me)  \n",
    "(I'm just providing the code of the for loop so that the reviewer can check my understanding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_diffs = np.zeros(10000)\n",
    "for i in range(10000):\n",
    "    \n",
    "    _sample = df2.sample(df2.shape[0],replace=True)\n",
    "    new_group = _sample.query('landing_page == \"new_page\"')\n",
    "    conv_new = new_group.converted.mean()\n",
    "    old_group = _sample.query('landing_page == \"old_page\"')\n",
    "    conv_old = old_group.converted.mean()\n",
    "    sample_p_new = np.random.choice([0,1],size=len(new_group),p=[1-p_new,p_new])\n",
    "    sample_p_old = np.random.choice([0,1],size=len(old_group),p=[1-p_old,p_old])\n",
    "    p_diffs[i] = sample_p_new.mean() - sample_p_old.mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00056233, -0.00024307,  0.00081675, ...,  0.00066546,\n",
       "       -0.00199792, -0.00081417])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_diffs = []\n",
    "#Using the binomial is an alternative to the for loop above , and it gives the same* results\n",
    "#* (possibly slightly different results but at a very small significance level)\n",
    "\n",
    "new_convert = np.random.binomial(n_new,p_new,10000)/n_new\n",
    "old_convert = np.random.binomial(n_old,p_old,10000)/n_old\n",
    "p_diffs = new_convert - old_convert\n",
    "p_diffs = np.array(p_diffs)\n",
    "p_diffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a histogram of the **p_diffs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   8.,   99.,  525., 1646., 2821., 2838., 1496.,  472.,   88.,\n",
       "           7.]),\n",
       " array([-4.65497007e-03, -3.71753640e-03, -2.78010273e-03, -1.84266906e-03,\n",
       "        -9.05235395e-04,  3.21982742e-05,  9.69631943e-04,  1.90706561e-03,\n",
       "         2.84449928e-03,  3.78193295e-03,  4.71936662e-03]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(p_diffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will plot the original difference found in the orignal data set, as a line on the plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   8.,   99.,  525., 1646., 2821., 2838., 1496.,  472.,   88.,\n",
       "           7.]),\n",
       " array([-4.65497007e-03, -3.71753640e-03, -2.78010273e-03, -1.84266906e-03,\n",
       "        -9.05235395e-04,  3.21982742e-05,  9.69631943e-04,  1.90706561e-03,\n",
       "         2.84449928e-03,  3.78193295e-03,  4.71936662e-03]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_avg_diff = new_mean - old_mean\n",
    "\n",
    "plt.axvline(x=original_avg_diff,color='red')\n",
    "plt.hist(p_diffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our alternative hypothesis is greater than the mean, then it seems that most of our data is actually greater than it, so maybe we won't reject the null? Let's check."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the proportion of the **p_diffs** are greater than the actual difference observed in the original data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9024"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_avg_diff = new_mean - old_mean\n",
    "(p_diffs > original_avg_diff).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the p-value is 0.9024, which is much greater than our error rate, 0.05.  \n",
    "So we fail to reject the null.  \n",
    "Which means that the new page design doesn't seem to offer an advantage.  \n",
    "Actually, from the previous data, it's possible that it will hinder the performance of the conversion process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l. We could also use a built-in to achieve similar results.  Though using the built-in might be easier to code, the above portions are a walkthrough of the ideas that are critical to correctly thinking about statistical significance. Fill in the below to calculate the number of conversions for each page, as well as the number of individuals who received each page. Let `n_old` and `n_new` refer the the number of rows associated with the old page and new pages, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I will use statsmodels api to compute the p-value for our hypothesis tests.  \n",
    "This is to make sure I didn't do any mistakes during my analysis.  \n",
    "First let's initialize some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "convert_old = df.query('landing_page == \"old_page\"').converted.sum()\n",
    "convert_new = df.query('landing_page == \"new_page\"').converted.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will use `stats.proportions_ztest` to compute the test statistic and p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.3109241984234394, 0.9050583127590245)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "stat, pval = proportions_ztest([convert_old,convert_new], [n_old,n_new],alternative = 'smaller')\n",
    "stat, pval = proportions_ztest([convert_new,convert_old], [n_new,n_old],alternative = 'larger')\n",
    "\n",
    "stat,pval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, the p-value is almost the same.  \n",
    "(That small difference could be because I used the binomial function, maybe using the for loop could have been more accurate, but this doesn't matter.)\n",
    "\n",
    "Looking at a z-score table, I can confirm that the z-score given corresponds to the same p-value calculated.  \n",
    "The -1.31.. corresponds to 0.0951.  \n",
    "Because that z-score gives us the area (or p-value) for the left, we should subtract it from 1 to get  \n",
    "0.905.  \n",
    "Which is the required.  \n",
    "\n",
    "**All in all, this means that based on this test as well, the company shouldn't go for the new page, yet.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='regression'></a>\n",
    "### Part III - A regression approach\n",
    "\n",
    "\n",
    "Now I will do a logistic regression to be more confident in the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. The goal is to use **statsmodels** to fit the regression model you specified in part **a.** to see if there is a significant difference in conversion based on which page a customer receives. However, you first need to create in df2 a column for the intercept, and create a dummy variable column for which page each user received.  Add an **intercept** column, as well as an **ab_page** column, which is 1 when an individual receives the **treatment** and 0 if **control**.\n",
    "\n",
    "I will use statsmodels as required to make the logistic regression model.  \n",
    "First, we need an intercept column.  \n",
    "Second, we need a dummy column in place of the landing_page column.  \n",
    "\n",
    "So let's make those first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp landing_page  converted  intercept  \\\n",
       "0   851104  2017-01-21 22:11:48.556739     old_page          0          1   \n",
       "1   804228  2017-01-12 08:01:45.159739     old_page          0          1   \n",
       "2   661590  2017-01-11 16:55:06.154213     new_page          0          1   \n",
       "3   853541  2017-01-08 18:28:03.143765     new_page          0          1   \n",
       "4   864975  2017-01-21 01:52:26.210827     old_page          1          1   \n",
       "\n",
       "   ab_page  \n",
       "0        0  \n",
       "1        0  \n",
       "2        1  \n",
       "3        1  \n",
       "4        0  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['intercept'] = 1\n",
    "#Get the dummies. This returns two columns\n",
    "dummies = pd.get_dummies(df['landing_page'])\n",
    "#Get only one of the two columns\n",
    "df['ab_page'] = dummies.iloc[:,0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Use **statsmodels** to instantiate your regression model on the two columns you created in part b., then fit the model using the two columns you created in part **b.** to predict whether or not an individual converts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366118\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "log_ml = sm.Logit(df['converted'],df[['intercept','ab_page']])\n",
    "results = log_ml.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Provide the summary of your model below, and use it as necessary to answer the following questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290582</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     1</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 20 Feb 2020</td> <th>  Pseudo R-squ.:     </th>  <td>8.077e-06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>19:04:03</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>   <td>0.1899</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -1.9888</td> <td>    0.008</td> <td> -246.669</td> <td> 0.000</td> <td>   -2.005</td> <td>   -1.973</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>   -0.0150</td> <td>    0.011</td> <td>   -1.311</td> <td> 0.190</td> <td>   -0.037</td> <td>    0.007</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290582\n",
       "Method:                           MLE   Df Model:                            1\n",
       "Date:                Thu, 20 Feb 2020   Pseudo R-squ.:               8.077e-06\n",
       "Time:                        19:04:03   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "Covariance Type:            nonrobust   LLR p-value:                    0.1899\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9888      0.008   -246.669      0.000      -2.005      -1.973\n",
       "ab_page       -0.0150      0.011     -1.311      0.190      -0.037       0.007\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value here for the ab_page is 0.19.  \n",
    "While smaller than the p-value we got from our hypothesis test, it still gives us the same conclusion.\n",
    "\n",
    "However, the reason it's different is because our null and alternative hypotheses when using logistic regression are as follows:\n",
    "\n",
    "$Ho: P_{new} - P_{old}  = 0$  \n",
    "$H1: P_{new} - P_{old}  \\neq 0$\n",
    "\n",
    "So it's a two tailed test, regardless of whether the new page performs better or worse, what matters here is that it performed in a notably different way.    \n",
    "But our original hypothesis test was a one tailed test: Greater than only.  \n",
    "From that we can also note that it's more likely that there is a difference in the performance of the two pages than that the new page performed better, albiet both probabilities are small and neglibible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Now, you are considering other things that might influence whether or not an individual converts.  Discuss why it is a good idea to consider other factors to add into your regression model.  Are there any disadvantages to adding additional terms into your regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are certainly other things that affect whether an individual would convert or not:\n",
    "1. The time spent on the page\n",
    "2. Number of general clicks or views (i.e. how many items had the individual viewed inside the page?)\n",
    "3. Interest in the affair. Uninterested individuals won't convert either way.\n",
    "\n",
    "But there are some drawbacks, most notably:\n",
    "1. Having many terms/features would make it harder to understand the results/conclusions\n",
    "2. We might be more prone to overfitting our data\n",
    "3. Sometimes new terms don't add much to the accuracy of our model, so they may not be very much useful\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g. Now along with testing if the conversion rate changes for different pages, also add an effect based on which country a user lives in. You will need to read in the **countries.csv** dataset and merge together your datasets on the appropriate rows.  [Here](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.join.html) are the docs for joining tables. \n",
    "\n",
    "Does it appear that country had an impact on conversion?  Don't forget to create dummy variables for these country columns - **Hint: You will need two columns for the three dummy variables.** Provide the statistical output as well as a written response to answer this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>834778</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>928468</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>822059</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>711597</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>710616</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id country\n",
       "0   834778      UK\n",
       "1   928468      US\n",
       "2   822059      UK\n",
       "3   711597      UK\n",
       "4   710616      UK"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries = pd.read_csv('countries.csv')\n",
    "countries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp landing_page  converted  intercept  \\\n",
       "0   851104  2017-01-21 22:11:48.556739     old_page          0          1   \n",
       "1   804228  2017-01-12 08:01:45.159739     old_page          0          1   \n",
       "2   661590  2017-01-11 16:55:06.154213     new_page          0          1   \n",
       "3   853541  2017-01-08 18:28:03.143765     new_page          0          1   \n",
       "4   864975  2017-01-21 01:52:26.210827     old_page          1          1   \n",
       "\n",
       "   ab_page country  \n",
       "0        0      US  \n",
       "1        0      US  \n",
       "2        1      US  \n",
       "3        1      US  \n",
       "4        0      US  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_m =  df.merge(countries,on=['user_id'],how='inner')\n",
    "df_m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US    203619\n",
       "UK     72466\n",
       "CA     14499\n",
       "Name: country, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries.country.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>country</th>\n",
       "      <th>CA</th>\n",
       "      <th>UK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp landing_page  converted  intercept  \\\n",
       "0   851104  2017-01-21 22:11:48.556739     old_page          0          1   \n",
       "1   804228  2017-01-12 08:01:45.159739     old_page          0          1   \n",
       "2   661590  2017-01-11 16:55:06.154213     new_page          0          1   \n",
       "3   853541  2017-01-08 18:28:03.143765     new_page          0          1   \n",
       "4   864975  2017-01-21 01:52:26.210827     old_page          1          1   \n",
       "\n",
       "   ab_page country  CA  UK  \n",
       "0        0      US   0   0  \n",
       "1        0      US   0   0  \n",
       "2        1      US   0   0  \n",
       "3        1      US   0   0  \n",
       "4        0      US   0   0  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We have three countries:\n",
    "dummies = pd.get_dummies(df_m['country'])\n",
    "\n",
    "#Here, if both CA and UK are 0, it means the country is US\n",
    "df_m[['CA','UK']] = dummies.iloc[:,0:2]\n",
    "\n",
    "df_m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366113\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290580</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     3</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 20 Feb 2020</td> <th>  Pseudo R-squ.:     </th>  <td>2.323e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>19:04:27</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>   <td>0.1760</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -1.9893</td> <td>    0.009</td> <td> -223.763</td> <td> 0.000</td> <td>   -2.007</td> <td>   -1.972</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>   -0.0149</td> <td>    0.011</td> <td>   -1.307</td> <td> 0.191</td> <td>   -0.037</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CA</th>        <td>   -0.0408</td> <td>    0.027</td> <td>   -1.516</td> <td> 0.130</td> <td>   -0.093</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK</th>        <td>    0.0099</td> <td>    0.013</td> <td>    0.743</td> <td> 0.457</td> <td>   -0.016</td> <td>    0.036</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290580\n",
       "Method:                           MLE   Df Model:                            3\n",
       "Date:                Thu, 20 Feb 2020   Pseudo R-squ.:               2.323e-05\n",
       "Time:                        19:04:27   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "Covariance Type:            nonrobust   LLR p-value:                    0.1760\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9893      0.009   -223.763      0.000      -2.007      -1.972\n",
       "ab_page       -0.0149      0.011     -1.307      0.191      -0.037       0.007\n",
       "CA            -0.0408      0.027     -1.516      0.130      -0.093       0.012\n",
       "UK             0.0099      0.013      0.743      0.457      -0.016       0.036\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_ml_c = sm.Logit(df_m['converted'],df_m[['intercept','ab_page','CA','UK']])\n",
    "results = log_ml_c.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the coefficeints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0099491671175422, 0.9600211149716509)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(0.0099),np.exp(-0.0408)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can say that if the individual is from the UK, then it's 1.009 more likely that they would convert than if they were from the US.\n",
    "Similarly, if the individual is from CA, it's 0.96 more likely that would would convert than if they were from the US, in other words, they are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0416437559600236"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(0.0408) # = 1/exp(-0.0408)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.041 less likely to convert than if they were from the US.\n",
    "\n",
    "Are these figures significant? They aren't, in my opinion.\n",
    "\n",
    "Also, looking at the p-values of each, they don't seem to contribue much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h. Though you have now looked at the individual factors of country and page on conversion, we would now like to look at an interaction between page and country to see if there significant effects on conversion.  Create the necessary additional columns, and fit the new model.  \n",
    "\n",
    "Provide the summary results, and your conclusions based on the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see more closely how each country affects the conversion, I will make a column for the interaction between ab_page and CA, and another column for the interaction between ab_page and UK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>country</th>\n",
       "      <th>CA</th>\n",
       "      <th>UK</th>\n",
       "      <th>ab_page_CA</th>\n",
       "      <th>ab_page_UK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp landing_page  converted  intercept  \\\n",
       "0   851104  2017-01-21 22:11:48.556739     old_page          0          1   \n",
       "1   804228  2017-01-12 08:01:45.159739     old_page          0          1   \n",
       "2   661590  2017-01-11 16:55:06.154213     new_page          0          1   \n",
       "3   853541  2017-01-08 18:28:03.143765     new_page          0          1   \n",
       "4   864975  2017-01-21 01:52:26.210827     old_page          1          1   \n",
       "\n",
       "   ab_page country  CA  UK  ab_page_CA  ab_page_UK  \n",
       "0        0      US   0   0           0           0  \n",
       "1        0      US   0   0           0           0  \n",
       "2        1      US   0   0           0           0  \n",
       "3        1      US   0   0           0           0  \n",
       "4        0      US   0   0           0           0  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_m['ab_page_CA'] = df_m['ab_page'] * df_m['CA']\n",
    "df_m['ab_page_UK'] = df_m['ab_page'] * df_m['UK']\n",
    "df_m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366109\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290578</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     5</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 20 Feb 2020</td> <th>  Pseudo R-squ.:     </th>  <td>3.482e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>19:04:54</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>   <td>0.1920</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>  <td>   -1.9865</td> <td>    0.010</td> <td> -206.344</td> <td> 0.000</td> <td>   -2.005</td> <td>   -1.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>    <td>   -0.0206</td> <td>    0.014</td> <td>   -1.505</td> <td> 0.132</td> <td>   -0.047</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CA</th>         <td>   -0.0175</td> <td>    0.038</td> <td>   -0.465</td> <td> 0.642</td> <td>   -0.091</td> <td>    0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK</th>         <td>   -0.0057</td> <td>    0.019</td> <td>   -0.306</td> <td> 0.760</td> <td>   -0.043</td> <td>    0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page_CA</th> <td>   -0.0469</td> <td>    0.054</td> <td>   -0.872</td> <td> 0.383</td> <td>   -0.152</td> <td>    0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page_UK</th> <td>    0.0314</td> <td>    0.027</td> <td>    1.181</td> <td> 0.238</td> <td>   -0.021</td> <td>    0.084</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290578\n",
       "Method:                           MLE   Df Model:                            5\n",
       "Date:                Thu, 20 Feb 2020   Pseudo R-squ.:               3.482e-05\n",
       "Time:                        19:04:54   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "Covariance Type:            nonrobust   LLR p-value:                    0.1920\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9865      0.010   -206.344      0.000      -2.005      -1.968\n",
       "ab_page       -0.0206      0.014     -1.505      0.132      -0.047       0.006\n",
       "CA            -0.0175      0.038     -0.465      0.642      -0.091       0.056\n",
       "UK            -0.0057      0.019     -0.306      0.760      -0.043       0.031\n",
       "ab_page_CA    -0.0469      0.054     -0.872      0.383      -0.152       0.059\n",
       "ab_page_UK     0.0314      0.027      1.181      0.238      -0.021       0.084\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_interaction = sm.Logit(df_m['converted'],df_m[['intercept','ab_page','CA','UK','ab_page_CA','ab_page_UK']])\n",
    "results = log_interaction.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To interpret the coefficients, I can write the logistic regression equation:  \n",
    "$LogP(Y=1) = B0 + B1_{page} + B2_{CA} + B3_{UK} + B4_{page * CA} + B5_{ab_page * UK}$  \n",
    "\n",
    "Assuming individual is canadian, B3 and B5 will be zero, so:  \n",
    "$LogP(Y=1) = B0 + B1_{page} + B2_{CA} + B4_{page * {CA}}$  \n",
    "\n",
    "I can rewrite it as:  \n",
    "$LogP(Y=1) = B0 + [B1 + B4_{CA}]_{page} + B2_{CA}$  \n",
    "\n",
    "Then, B1 + B4_CA is the conersion odds ratio for new page vs old page.   \n",
    "And B2 is conversion odds ration for canadians vs non canadians.  \n",
    "\n",
    "So B4 is the difference between conversion odds ratio for canadians vs non canadians and conversion odds for individuals on the new page vs old page.\n",
    "Same can be done to see that B5 is the difference between conversion odds ratio for UK vs non canadians and conversion odds for individuals on the new page vs old page.\n",
    "\n",
    "B4 = -0.0469 and B5 =  0.0314  \n",
    "Calculating the coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9541828111007262, 1.0318981806179213)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-0.0469),np.exp(0.0314)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out the interaction doesn't make much of an effect.  \n",
    "Since the values I got from exponentiation are quite close to 1, which in turns means that the difference in conversion odds are negligible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: Adding a time feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would like to see if the timestamp of the page view does affect the conversion.\n",
    "I will use logistic regression here.\n",
    "\n",
    "First, I need to convert string date to datetime object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 290584 entries, 0 to 290583\n",
      "Data columns (total 11 columns):\n",
      "user_id         290584 non-null int64\n",
      "timestamp       290584 non-null datetime64[ns]\n",
      "landing_page    290584 non-null object\n",
      "converted       290584 non-null int64\n",
      "intercept       290584 non-null int64\n",
      "ab_page         290584 non-null uint8\n",
      "country         290584 non-null object\n",
      "CA              290584 non-null uint8\n",
      "UK              290584 non-null uint8\n",
      "ab_page_CA      290584 non-null uint8\n",
      "ab_page_UK      290584 non-null uint8\n",
      "dtypes: datetime64[ns](1), int64(3), object(2), uint8(5)\n",
      "memory usage: 16.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_m.timestamp = pd.to_datetime(df_m.timestamp)\n",
    "df_m.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will partition entries into four categories:  \n",
    "1. after mid night: from 0 till 6   \n",
    "2. morning: from 6 till 12  \n",
    "3. after noon: from 12 till 18  \n",
    "4. night: from 18 till 24  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>country</th>\n",
       "      <th>CA</th>\n",
       "      <th>UK</th>\n",
       "      <th>ab_page_CA</th>\n",
       "      <th>ab_page_UK</th>\n",
       "      <th>period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>afternoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mid_night</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                  timestamp landing_page  converted  intercept  \\\n",
       "0   851104 2017-01-21 22:11:48.556739     old_page          0          1   \n",
       "1   804228 2017-01-12 08:01:45.159739     old_page          0          1   \n",
       "2   661590 2017-01-11 16:55:06.154213     new_page          0          1   \n",
       "3   853541 2017-01-08 18:28:03.143765     new_page          0          1   \n",
       "4   864975 2017-01-21 01:52:26.210827     old_page          1          1   \n",
       "\n",
       "   ab_page country  CA  UK  ab_page_CA  ab_page_UK     period  \n",
       "0        0      US   0   0           0           0      night  \n",
       "1        0      US   0   0           0           0    morning  \n",
       "2        1      US   0   0           0           0  afternoon  \n",
       "3        1      US   0   0           0           0      night  \n",
       "4        0      US   0   0           0           0  mid_night  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First I will add a column that has 0 for hours less than 6, 1 for hours between 6 and 12, 2 for hours 12-18, and 3 for 18-24\n",
    "#The remainder and division functions do the math for us\n",
    "df_m['period'] = (df_m['timestamp'].dt.hour % 24) // 6  \n",
    "#Give each number a name that represents it\n",
    "df_m['period'].replace({0:'mid_night',1:'morning',2:'afternoon',3:'night'},inplace=True)\n",
    "df_m.head()          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>country</th>\n",
       "      <th>CA</th>\n",
       "      <th>UK</th>\n",
       "      <th>ab_page_CA</th>\n",
       "      <th>ab_page_UK</th>\n",
       "      <th>period</th>\n",
       "      <th>afternoon</th>\n",
       "      <th>mid_night</th>\n",
       "      <th>morning</th>\n",
       "      <th>night</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>night</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>morning</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>night</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mid_night</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                  timestamp landing_page  converted  intercept  \\\n",
       "0   851104 2017-01-21 22:11:48.556739     old_page          0          1   \n",
       "1   804228 2017-01-12 08:01:45.159739     old_page          0          1   \n",
       "2   661590 2017-01-11 16:55:06.154213     new_page          0          1   \n",
       "3   853541 2017-01-08 18:28:03.143765     new_page          0          1   \n",
       "4   864975 2017-01-21 01:52:26.210827     old_page          1          1   \n",
       "\n",
       "   ab_page country  CA  UK  ab_page_CA  ab_page_UK     period  afternoon  \\\n",
       "0        0      US   0   0           0           0      night          0   \n",
       "1        0      US   0   0           0           0    morning          0   \n",
       "2        1      US   0   0           0           0  afternoon          1   \n",
       "3        1      US   0   0           0           0      night          0   \n",
       "4        0      US   0   0           0           0  mid_night          0   \n",
       "\n",
       "   mid_night  morning  night  \n",
       "0          0        0      1  \n",
       "1          0        1      0  \n",
       "2          0        0      0  \n",
       "3          0        0      1  \n",
       "4          1        0      0  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now make a new dummy column for each period using get_dummies\n",
    "periods_dummies = pd.get_dummies(df_m['period'])\n",
    "df_m[['afternoon','mid_night','morning','night']] = periods_dummies\n",
    "df_m.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me see first how does the time affect the conversion directly, along with the page. I will use morning as a base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366100\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290579</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     4</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 20 Feb 2020</td> <th>  Pseudo R-squ.:     </th>  <td>5.793e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>19:05:15</td>     <th>  Log-Likelihood:    </th> <td>-1.0638e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>   <td>0.01509</td>  \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -1.9804</td> <td>    0.013</td> <td> -155.568</td> <td> 0.000</td> <td>   -2.005</td> <td>   -1.955</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>   -0.0149</td> <td>    0.011</td> <td>   -1.307</td> <td> 0.191</td> <td>   -0.037</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>afternoon</th> <td>    0.0007</td> <td>    0.016</td> <td>    0.043</td> <td> 0.966</td> <td>   -0.031</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>night</th>     <td>    0.0060</td> <td>    0.016</td> <td>    0.373</td> <td> 0.709</td> <td>   -0.026</td> <td>    0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mid_night</th> <td>   -0.0407</td> <td>    0.016</td> <td>   -2.502</td> <td> 0.012</td> <td>   -0.073</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290579\n",
       "Method:                           MLE   Df Model:                            4\n",
       "Date:                Thu, 20 Feb 2020   Pseudo R-squ.:               5.793e-05\n",
       "Time:                        19:05:15   Log-Likelihood:            -1.0638e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "Covariance Type:            nonrobust   LLR p-value:                   0.01509\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9804      0.013   -155.568      0.000      -2.005      -1.955\n",
       "ab_page       -0.0149      0.011     -1.307      0.191      -0.037       0.007\n",
       "afternoon      0.0007      0.016      0.043      0.966      -0.031       0.032\n",
       "night          0.0060      0.016      0.373      0.709      -0.026       0.038\n",
       "mid_night     -0.0407      0.016     -2.502      0.012      -0.073      -0.009\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_md_time = sm.Logit(df_m['converted'],df_m[['intercept','ab_page','afternoon','night','mid_night']])\n",
    "results = log_md_time.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestengly, it seems that mid_night period is less likely to have conversions than the morning period.  \n",
    "Because it's coefficient is negative, which means if we take the positive like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0415395967924728"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(0.0407)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it's 1.04 less likely that a conversion takes place if it were in mid night than in morning.  \n",
    "Other periods don't affect the conversion much compared to morning since their coefficient is small.  \n",
    "\n",
    "Also, looking at p-values, mid_night has one at 0.012 which means it does have an effect on converting..  \n",
    "while other periods don't affect much, again compared to morning.  \n",
    "**All in all**, it seems that _conversion takes place mostly on morning, afternoon, and night_ periods.  \n",
    "Which makes sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if this will change when incorporating the countries;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366095\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290577</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     6</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 20 Feb 2020</td> <th>  Pseudo R-squ.:     </th>  <td>7.312e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>19:06:02</td>     <th>  Log-Likelihood:    </th> <td>-1.0638e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>   <td>0.01633</td>  \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -1.9809</td> <td>    0.013</td> <td> -149.186</td> <td> 0.000</td> <td>   -2.007</td> <td>   -1.955</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>   -0.0149</td> <td>    0.011</td> <td>   -1.303</td> <td> 0.193</td> <td>   -0.037</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CA</th>        <td>   -0.0408</td> <td>    0.027</td> <td>   -1.516</td> <td> 0.129</td> <td>   -0.093</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK</th>        <td>    0.0099</td> <td>    0.013</td> <td>    0.748</td> <td> 0.455</td> <td>   -0.016</td> <td>    0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>afternoon</th> <td>    0.0006</td> <td>    0.016</td> <td>    0.036</td> <td> 0.971</td> <td>   -0.031</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>night</th>     <td>    0.0060</td> <td>    0.016</td> <td>    0.371</td> <td> 0.711</td> <td>   -0.026</td> <td>    0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mid_night</th> <td>   -0.0407</td> <td>    0.016</td> <td>   -2.506</td> <td> 0.012</td> <td>   -0.073</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290577\n",
       "Method:                           MLE   Df Model:                            6\n",
       "Date:                Thu, 20 Feb 2020   Pseudo R-squ.:               7.312e-05\n",
       "Time:                        19:06:02   Log-Likelihood:            -1.0638e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "Covariance Type:            nonrobust   LLR p-value:                   0.01633\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9809      0.013   -149.186      0.000      -2.007      -1.955\n",
       "ab_page       -0.0149      0.011     -1.303      0.193      -0.037       0.008\n",
       "CA            -0.0408      0.027     -1.516      0.129      -0.093       0.012\n",
       "UK             0.0099      0.013      0.748      0.455      -0.016       0.036\n",
       "afternoon      0.0006      0.016      0.036      0.971      -0.031       0.032\n",
       "night          0.0060      0.016      0.371      0.711      -0.026       0.038\n",
       "mid_night     -0.0407      0.016     -2.506      0.012      -0.073      -0.009\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_md_time = sm.Logit(df_m['converted'],df_m[['intercept','ab_page','CA','UK','afternoon','night','mid_night']])\n",
    "results = log_md_time.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got almost the exact coef. we got before for the time periods.  \n",
    "And we got a very similar coef. for CA and UK compared to our first model with countries.  \n",
    "What this means is that there isn't much of a correlation between time periods and countries.  \n",
    "That may be because each timestamp was registered at the local time of the individual.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusions'></a>\n",
    "## Finishing Up\n",
    "\n",
    "The testing methods performed here are a strong evidence that the new page didn't offer much of an advantage over the old page.  \n",
    "Running the experiment longer may be helpful, but since almost no difference between the two pages have been seen, I suspect that dropping that new page design for another one, or perhaps keeping the same old page, would both be wiser choices\n",
    "\n",
    "## Directions to Submit\n",
    "\n",
    "> Before you submit your project, you need to create a .html or .pdf version of this notebook in the workspace here. To do that, run the code cell below. If it worked correctly, you should get a return code of 0, and you should see the generated .html file in the workspace directory (click on the orange Jupyter icon in the upper left).\n",
    "\n",
    "> Alternatively, you can download this report as .html via the **File** > **Download as** submenu, and then manually upload it into the workspace directory by clicking on the orange Jupyter icon in the upper left, then using the Upload button.\n",
    "\n",
    "> Once you've done this, you can submit your project by clicking on the \"Submit Project\" button in the lower right here. This will create and submit a zip file with this .ipynb doc and the .html or .pdf version you created. Congratulations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from subprocess import call\n",
    "call(['python', '-m', 'nbconvert', 'Analyze_ab_test_results_notebook.ipynb'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "Logistic regression interaction interpretation\n",
    "\n",
    "http://www.cantab.net/users/filimon/cursoFCDEF/will/logistic_interact.pdf\n",
    "\n",
    "Answers here helped me:\n",
    "\n",
    "https://stackoverflow.com/questions/55571311/get-part-of-day-morning-afternoon-evening-night-in-python-dataframe\n",
    "\n",
    "https://stackoverflow.com/questions/32204631/how-to-convert-string-to-datetime-format-in-pandas-python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
